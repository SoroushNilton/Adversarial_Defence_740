{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53313,"status":"ok","timestamp":1682568143664,"user":{"displayName":"Soroush Razavi","userId":"10452039528420675410"},"user_tz":360},"id":"Hoef0HHydXmf","outputId":"df03de54-2142-4cb0-ed68-3cd36eafca90"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!cp -r /content/drive/MyDrive/740_deeplearning/* /content/\n","!cp -r /content/drive/MyDrive/740_deeplearning/Novelty/* /content/"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4128,"status":"ok","timestamp":1682568150532,"user":{"displayName":"Soroush Razavi","userId":"10452039528420675410"},"user_tz":360},"id":"7dpgSrzzdXmm"},"outputs":[],"source":["import math\n","import torch.nn as nn\n","from collections import OrderedDict\n","\n","\n","norm_mean, norm_var = 0.0, 1.0\n","\n","defaultcfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 512]\n","relucfg = [2, 6, 9, 13, 16, 19, 23, 26, 29, 33, 36, 39]\n","convcfg = [0, 3, 7, 10, 14, 17, 20, 24, 27, 30, 34, 37]\n","\n","\n","\n","class VGG(nn.Module):\n","    def __init__(self, num_classes=10, init_weights=True, cfg=None, compress_rate=None):\n","        super(VGG, self).__init__()\n","        self.features = nn.Sequential()\n","\n","        if cfg is None:\n","            cfg = defaultcfg\n","\n","        self.relucfg = relucfg\n","        self.covcfg = convcfg\n","        self.compress_rate = compress_rate\n","        self.features = self.make_layers(cfg[:-1], True, compress_rate)\n","        self.classifier = nn.Sequential(OrderedDict([\n","            ('linear1', nn.Linear(cfg[-2], cfg[-1])),\n","            ('norm1', nn.BatchNorm1d(cfg[-1])),\n","            ('relu1', nn.ReLU(inplace=True)),\n","            ('linear2', nn.Linear(cfg[-1], num_classes)),\n","        ]))\n","\n","        if init_weights:\n","            self._initialize_weights()\n","\n","    def make_layers(self, cfg, batch_norm=True, compress_rate=None):\n","        layers = nn.Sequential()\n","        in_channels = 3\n","        cnt = 0\n","        for i, v in enumerate(cfg):\n","            if v == 'M':\n","                layers.add_module('pool%d' % i, nn.MaxPool2d(kernel_size=2, stride=2))\n","            else:\n","                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n","                conv2d.cp_rate = compress_rate[cnt]\n","                cnt += 1\n","\n","                layers.add_module('conv%d' % i, conv2d)\n","                layers.add_module('norm%d' % i, nn.BatchNorm2d(v))\n","                layers.add_module('relu%d' % i, nn.ReLU(inplace=True))\n","                in_channels = v\n","\n","        return layers\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","\n","        x = nn.AvgPool2d(2)(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.classifier(x)\n","        return x\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(0.5)\n","                m.bias.data.zero_()\n","            elif isinstance(m, nn.Linear):\n","                m.weight.data.normal_(0, 0.01)\n","                m.bias.data.zero_()\n","\n","\n","def vgg_16_bn(compress_rate=[0.95]+[0.5]*6+[0.9]*4+[0.8]*2):\n","    return VGG(compress_rate=compress_rate)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sfgf33eKdXmo","outputId":"469c3209-4ca3-4272-b331-b7b8858c58a3"},"outputs":[],"source":["import os\n","import warnings\n","import torch\n","import torchvision.datasets as datasets\n","import torch.utils.data as data\n","import torchvision.transforms as transforms\n","from autoattack import AutoAttack\n","from torchvision.datasets import CIFAR10\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","\n","# Load model\n","def load_model(model_path):\n","    model = vgg_16_bn()\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    ckpt = torch.load(model_path, map_location=device)\n","    model.load_state_dict(ckpt['state_dict'])\n","    model.to(device)\n","    model.eval()\n","    return model\n","\n","# Load data\n","def load_data(data_dir):\n","    pin_memory = True\n","\n","    transform_test = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","            ])\n","\n","    testset = CIFAR10(root=data_dir, train=False, download=True, transform=transform_test)\n","    loader_test = DataLoader(\n","            testset, batch_size=1024, shuffle=False, \n","            num_workers=2, pin_memory=pin_memory)\n","        \n","    return loader_test\n","\n","# Create save directory\n","def create_save_dir(save_dir):\n","    os.makedirs(save_dir, exist_ok=True)\n","\n","# Get attack\n","def get_attack(model, norm, epsilon, log_path, version):\n","    adversary = AutoAttack(model, norm=norm, eps=epsilon,\n","                           log_path=log_path, version=version)\n","    return adversary\n","\n","def main():\n","    warnings.filterwarnings(\"ignore\")\n","\n","    data_dir = './data'\n","    norm = 'L2'  # Linf\n","    epsilon = 8. / 255.\n","    model_path = '/content/drive/MyDrive/740_deeplearning/Novelty/CRANK_vgg_16_bn_cov12.pt'\n","    # model_path = '/content/drive/MyDrive/740_deeplearning/Novelty/HRANK_vgg_16_bn_cov12.pt'\n","    # model_path = '/content/drive/MyDrive/740_deeplearning/Novelty/vgg_16_bn.pt'\n","    individual = False\n","    save_dir = f'./content/drive/MyDrive/740_deeplearning/Novelty/results_CRANK/AA_results_cifar10_{norm}'\n","    # save_dir = f'./content/drive/MyDrive/740_deeplearning/Novelty/results_HRANK/AA_results_cifar10_{norm}'\n","    # save_dir = f'./content/drive/MyDrive/740_deeplearning/Novelty/results_no_pretrain/AA_results_cifar10_{norm}'\n","    batch_size = 1024\n","    version = 'standard'\n","    state_path = None\n","\n","    create_save_dir(save_dir)\n","    log_path = os.path.join(save_dir, 'log_file.txt')\n","\n","    model = load_model(model_path)\n","    test_loader = load_data(data_dir)\n","    n_ex = len(test_loader.dataset)\n","\n","    # Get data and labels from test_loader\n","    x_test = torch.cat([x for (x, y) in test_loader], 0)\n","    y_test = torch.cat([y for (x, y) in test_loader], 0)\n","    \n","    adversary = get_attack(model, norm, epsilon, log_path, version)\n","\n","    with torch.no_grad():\n","        if not individual:\n","\n","            adv_complete = adversary.run_standard_evaluation(x_test[:n_ex], y_test[:n_ex],\n","                                                              bs=batch_size, state_path=state_path)\n","\n","            torch.save({'adv_complete': adv_complete}, f'{save_dir}/aa_{version}_1_{adv_complete.shape[0]}_eps_{epsilon:.5f}.pth')\n","            \n","        else:\n","\n","            adv_complete = adversary.run_standard_evaluation_individual(x_test[:n_ex],\n","                                                                        y_test[:n_ex], bs=batch_size)\n","            \n","            torch.save(adv_complete, f'{save_dir}/aa_{version}_individual_1_{n_ex}_eps_{epsilon:.5f}.pth')\n","\n","if __name__ == '__main__':\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VEp6GBMY5zgA"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
